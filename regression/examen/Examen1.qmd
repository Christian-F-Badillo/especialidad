---
title: "Examen 1"
subtitle: "Regresión"
author: "Christian Badillo"
format: 
    html:
        code-fold: true
        code-summary: "Click para ver el código"
        toc: true
        toc-location: left
        toc-depth: 3
        number-sections: true
        fig-width: 6
        fig-height: 4
        fig-cap: "Figure {#fig-1} Caption"
        grid:
            margin-width: 0px
            body-width: 1400px
            sidebar-width: 200px
        crossref: 
            fig-prefix: "figura"
            tbl-prefix: "tabla"

date: today
date-format: long
lang: es
cache: true
freeze: auto
---
```{r}
#| echo: false
#| warning: false
# Librerias
library(tidyverse)
library(ggplot2)
library(tidyplots)
library(dplyr)
library(knitr)
library(kableExtra)
library(plotly)
library(modelsummary)
library(mice)
library(ggmice)
library(MASS)
library(car)
library(nortest)
library(FactoMineR)
library(factoextra)
library(ggbiplot)
library(forecast)

datos <- read.csv("Lifexpectancy.csv")
```

# Teórico

## Ejercicio 1.

**Prueba de dos muestras**. Sean $\bar{y_i}$ con $i = 0, 1$ las medias de dos muestras con tamaños $m_0$ y $m_1$ y desviaciones estándar $SD_0$ y $SD_1$ respectivamente. Si la muestra $j$ se distribuye $N(\mu_j, \sigma^2)$, entonces el estadístico:

$$
T = \frac{\bar{y_0} - \bar{y_i}}{\hat{\sigma} \sqrt{\frac{1}{m_0} + \frac{1}{m_1}}}
$$

donde $\hat{\sigma} = \frac{(m_0-1)SD_0^2 + (m_1 - 1)SD_1^2}{m_0 + m_1 - 2}$ se usa para la prueba de hipótesis $\mu_0 = \mu_1$, con distribución nula $T \sim t_{(m_0 + m_1 - 2)}$.

Supongamos primero que el tamaño muestral es el mismo para ambas muestras. Definiendo $X$ como la variable explicativa de tal forma que tiene $0$ en sus primeras $m$ entradas y $1$ en las restantes $m$, y un vector respuesta $Y$ como variable respuesta con las $2m$ observaciones concatenadas. Muestra que el modelo de regresión lineal simple es equivalente al problema de dos muestras de la siguiente manera.

* Calcula las medias y sumas de cuadrados para este modelo, con ésto, calcula los estimadores por mínimos cuadrados e interprétalos.

Para el método de mínimos cuadrados, se tiene que minimizar la suma de cuadrados de los residuos:
$$
\sum_{i=1}^{2m} (y_i - \hat{y_i})^2
$$

donde $\hat{y_i} = \beta_0 + \beta_1 x_i$ y $\beta_0$ y $\beta_1$ son los parámetros a estimar. Para ello, tomamos las derivadas parciales respecto a $\beta_0$ y $\beta_1$ y las igualamos a cero. Esto nos da un sistema de ecuaciones que podemos resolver para encontrar los estimadores de mínimos cuadrados.

\begin{align*}
\frac{\partial}{\partial \beta_0} \sum_{i=1}^{2m} (y_i - \hat{y_i})^2 &= 0 \\
\frac{\partial}{\partial \beta_1} \sum_{i=1}^{2m} (y_i - \hat{y_i})^2 &= 0
\end{align*}

Procedamos primeramente con $\beta_0$:

\begin{align*}
\frac{\partial}{\partial \beta_0} \sum_{i=1}^{2m} (y_i - \hat{y_i})^2 &= \frac{\partial}{\partial \beta_0} \sum_{i=1}^{2m} (y_i - (\beta_0 + \beta_1 x_i))^2 \\
&= \sum_{i=1}^{2m} -2(y_i - (\beta_0 + \beta_1 x_i)) = 0 \\
&= -2 \sum_{i=1}^{2m} (y_i - (\beta_0 + \beta_1 x_i)) = 0 \\
&= \sum_{i=1}^{2m} y_i - 2m \beta_0 - \beta_1 \sum_{i=1}^{2m} x_i = 0 \\
\end{align*}

Dado que $x_i$ es $0$ para los primeros $m$ y $1$ para los segundos $m$, tenemos que $\sum_{i=1}^{2m} x_i = m$. Por lo tanto, la ecuación se convierte en:
\begin{align*}
\sum_{i=1}^{2m} y_i - 2m \beta_0 - m \beta_1 = 0 \\
\sum_{i=1}^{2m} y_i = 2m \beta_0 + m \beta_1 \\
\beta_0 = \frac{1}{2m} \sum_{i=1}^{2m} y_i - \frac{1}{2} \beta_1
\end{align*}

Dado que la media de $y_i$ es $\bar{y} = \frac{1}{2m} \sum_{i=1}^{2m} y_i$, podemos reescribir la ecuación como:
$$
\beta_0 = \bar{y} - \frac{1}{2} \beta_1
$$

Procedemos ahora con $\beta_1$:
\begin{align*}
\frac{\partial}{\partial \beta_1} \sum_{i=1}^{2m} (y_i - \hat{y_i})^2 &= \frac{\partial}{\partial \beta_1} \sum_{i=1}^{2m} (y_i - (\beta_0 + \beta_1 x_i))^2 \\
&= \sum_{i=1}^{2m} -2(y_i - (\beta_0 + \beta_1 x_i)) x_i = 0 \\
&= -2 \sum_{i=1}^{2m} (y_i - (\beta_0 + \beta_1 x_i)) x_i = 0 \\
&= \sum_{i=1}^{2m} y_i x_i - \beta_0 \sum_{i=1}^{2m} x_i - \beta_1 \sum_{i=1}^{2m} x_i^2 = 0 \\
&= \sum_{i=1}^{m} y_i^1 - \beta_0 m - \beta_1 m = 0 \\
\end{align*}

donde $\sum_{i=1}^{m} y_i^1$ representa la suma de los valores para la muestra $1$, dado que el producto de $x_i$ por $y_i$ es $0$ para los primeros $m$ y $y_i$ para los segundos $m$. Por lo tanto, la ecuación se convierte en:
\begin{align*}
\sum_{i=1}^{m} y_i^1 - \beta_0 m - \beta_1 m = 0 \\
\sum_{i=1}^{m} y_i^1 = \beta_0 m + \beta_1 m \\
\beta_0 = \frac{1}{m} \sum_{i=1}^{m} y_i^1 - \beta_1
\end{align*}

En esta última igualdad podemos ver que $\frac{1}{m} \sum_{i=1}^{m} y_i^1 = \bar{y_1}$, por lo que podemos reescribir la ecuación como:
$$
\beta_1 = \bar{y_1} - \beta_0
$$

Reemplazamos $\beta_0$ en la ecuación de $\beta_1$, usando la propiedad de que $\bar{y} = \frac{1}{2}(\bar{y_0} + \bar{y_1})$:
\begin{align*}
\beta_1 &= \bar{y_1} - \left(\bar{y} - \frac{1}{2} \beta_1\right) \\
\beta_1 &= \frac{2\bar{y_1} - \bar{y_0} - \bar{y_1} + \beta_1}{2} \\
\frac{1}{2} \beta_1 &= \frac{\bar{y_1} - \bar{y_0}}{2} \\
\beta_1 &= \bar{y_1} - \bar{y_0}
\end{align*}

Resolviendo para $\beta_0$:
\begin{align*}
\beta_0 &= \bar{y} - \frac{1}{2} \beta_1 \\
&= \bar{y} - \frac{1}{2} (\bar{y_1} - \bar{y_0}) \\
&= \frac{1}{2} (\bar{y_0} + \bar{y_1}) - \frac{1}{2} (\bar{y_1} - \bar{y_0}) \\
&= \frac{1}{2} (\bar{y_0} + \bar{y_1}) - \frac{1}{2} \bar{y_1} + \frac{1}{2} \bar{y_0} \\
&= \frac{1}{2} \bar{y_0} + \frac{1}{2} \bar{y_0} \\
&= \bar{y_0}
\end{align*}
 
 Por lo tanto, los estimadores de mínimos cuadrados son:
\begin{align*}
\hat{\beta_0} &= \bar{y_0} \\
\hat{\beta_1} &= \bar{y_1} - \bar{y_0}
\end{align*}

Podemos interpretar a $\beta_0$ como el valor esperado en el grupo $0$ o de referencia y a $\beta_1$ como la diferencia de medias entre los grupos $0$ y $1$. Esto es, $\beta_1$ representa el cambio en la variable dependiente al cambiar de grupo $0$ a grupo $1$.

* Encuentra los valores ajustados y los residuales. Con ello, calcula $\sigma^2$.

Para calcular los valores ajustados, usamos la ecuación de regresión:
\begin{align*}
\hat{y_i} &= \hat{\beta_0} + \hat{\beta_1} x_i \\
&= \bar{y_0} + (\bar{y_1} - \bar{y_0}) x_i
\end{align*}

Los residuales son la diferencia entre los valores observados y los valores ajustados:
\begin{align*}
e_i &= y_i - \hat{y_i} \\
&= y_i - \left(\bar{y_0} + (\bar{y_1} - \bar{y_0}) x_i\right) \\
&= y_i - \bar{y_0} - (\bar{y_1} - \bar{y_0}) x_i
\end{align*}

Para calcular $\sigma^2$, usamos la suma de cuadrados de los residuales:
\begin{align*}
SSE &= \sum_{i=1}^{2m} e_i^2 \\
&= \sum_{i=1}^{2m} (y_i - \hat{y_i})^2 \\
&= \sum_{i=1}^{2m} (y_i - \left(\bar{y_0} + (\bar{y_1} - \bar{y_0}) x_i\right))^2
\end{align*}

Esta suma de cuadrados se puede dividir en dos partes, una para el grupo $0$ y otra para el grupo $1$:
\begin{align*}
SSE &= \sum_{i=1}^{m} (y_i^0 - \bar{y_0})^2 + \sum_{i=1}^{m} (y_i^1 - \bar{y_1})^2 \\
&= \sum_{i=1}^{m} (y_i^0 - \bar{y_0})^2 + \sum_{i=1}^{m} (y_i^1 - \bar{y_1})^2
\end{align*}

Donde $y_i^0$ y $y_i^1$ son los valores de la variable dependiente para el grupo $0$ y $1$, respectivamente. Usando la varianza muestral, podemos escribir:
$$
SSE = (m - 1)SD_0^2 + (m - 1)SD_1^2
$$

Dado el estimador de $\sigma^2$ como:
\begin{align*}
\hat{\sigma}^2 &= \frac{SSE}{2m - 2} \\
&= \frac{(m - 1)SD_0^2 + (m - 1)SD_1^2}{2m - 2} \\
&= \frac{(m - 1)(SD_0^2 + SD_1^2)}{2(m - 1)} \\
&= \frac{SD_0^2 + SD_1^2}{2}
\end{align*}

Por lo tanto, el estimador de $\sigma^2$ es la media de las varianzas muestrales de los dos grupos.

* Muestra que el estadístico T para la prueba $\beta_1 = 0$ es el mismo que para la prueba de
dos muestras.

La prueba de hipótesis para la regresión lineal simple para cualquiera parámetro $\beta_i$ es:
$$
t = \frac{\hat{\beta_i} - \beta_i}{\sqrt{Var(\hat{\beta_i})}}
$$

Para ello devemos calcular la varianza de $\hat{\beta_1}$ y suponiendo que la varianza de los errores es $\sigma^2$ para ambos grupos, tenemos que:
\begin{align*}
Var(\hat{\beta_1}) &= Var(\bar{y_1} - \bar{y_0}) \\
&= Var(\bar{y_1}) + Var(\bar{y_0}) \\
&= \frac{\sigma^2}{m} + \frac{\sigma^2}{m} \\
&= \frac{2\sigma^2}{m}
\end{align*}

Por lo tanto, la varianza de $\hat{\beta_1}$ es:
$$
Var(\hat{\beta_1}) = \frac{2\sigma^2}{m}
$$

Por ende, al reemplazar en la ecuación del estadístico T, tenemos que:
\begin{align*}
t &= \frac{\hat{\beta_1} - 0}{\sqrt{Var(\hat{\beta_1})}} \\
&= \frac{\hat{\beta_1}}{\sqrt{\frac{2\sigma^2}{m}}} \\
&= \frac{\hat{\beta_1}}{\hat{\sigma} \sqrt{\frac{2}{m}}} \\
&= \frac{\hat{\beta_1}}{\hat{\sigma} \sqrt{\frac{1}{m} + \frac{1}{m}}} \\
&= \frac{\bar{y_1} - \bar{y_0}}{\hat{\sigma} \sqrt{\frac{1}{m} + \frac{1}{m}}}
\end{align*}

Por lo tanto, el estadístico T para la prueba de hipótesis $\beta_1 = 0$ es el mismo que para la prueba de dos muestras, dado que ambos tienen la misma forma y distribución.

* ¿Qué ocurre si el tamaño muestral no coincide? Comenta sin demostración.

Para el caso los estimadores por mínimos cuadrados son idénticos para $\beta_1$ pero para el parámetro $\beta_0$ no es la media de la muestra del grupo $0$ sino que es una combinación lineal de las medias de ambos grupos. En este caso, el estadístico T para la prueba de hipótesis $\beta_1 = 0$ se convierte en su versión generalizada, que es:
$$
t = \frac{\hat{\beta_1}}{\hat{\sigma} \sqrt{\frac{1}{m_0} + \frac{1}{m_1}}}
$$

Y se realiza correción en $\sigma^2$ por los tamaños muestrales diferentes. En este caso, el estadístico T sigue una distribución t con $m_0 + m_1 - 2$ grados de libertad.

## Ejercicio 2.

Describe los componentes del modelo de regresión lineal múltiple.

El modelo de regresión lineal múltiple se puede escribir como:
$$
Y = X\beta + \epsilon, \hspace{2cm} \text{donde: } \epsilon \sim N(0, \sigma^2 I).
$$
Los componentes del modelo son:

- $Y$: Variable de respuesta, que es la variable que queremos predecir o explicar.
- $X$: Matriz de diseño, que contiene las variables explicativas o predictoras. Cada columna de la matriz representa una variable explicativa y cada fila representa una observación.
- $\beta$: Vector de coeficientes, que contiene los parámetros del modelo que queremos estimar. Cada elemento de este vector representa el efecto de una variable explicativa sobre la variable de respuesta.
- $\epsilon$: Término de error, que representa la variabilidad en la variable de respuesta que no se puede explicar por las variables explicativas. Se asume que este término sigue una distribución normal con media cero y varianza $\sigma^2$ y es la parte que da aleatoriedad al modelo.


## Ejercicio 3.
¿Cuáles son las ecuaciones normales del modelo? ¿Cómo podemos obtenerlas?

Las ecuaciones normales del modelo de regresión lineal múltiple se obtienen al minimizar la suma de cuadrados de los residuos. La suma de cuadrados de los residuos se puede escribir como:
$$
E = ||Y - X\beta||^2 = (Y - X\beta)^T (Y - X\beta)
$$
Minimizando $E$ respecto a $\beta$, obtenemos las ecuaciones normales:
$$
\beta = (X^T X)^{-1} X^T Y
$$
Suponiendo que $X^T X$ es invertible, esta ecuación nos da los estimadores de mínimos cuadrados para los coeficientes del modelo de regresión lineal múltiple. La matriz $(X^T X)^{-1} X^T$ se conoce como la matriz de proyección o *Hat Matrix* y se utiliza para proyectar los valores observados $Y$ en el espacio de las variables explicativas $X$.

4. ¿Qué es el factor de agrandamiento de varianza? ¿Y el criterio de AIC? Da ejemplos donde
muestres tus afirmaciones. Recuerda incluir gráficos que lo respalden.

El factor de agrandamiento de varianza (VIF) es una medida que se utiliza para detectar la multicolinealidad en un modelo de regresión lineal. La multicolinealidad ocurre cuando dos o más variables independientes están altamente correlacionadas entre sí, lo que puede dificultar la estimación precisa de los coeficientes del modelo. El VIF se calcula para cada variable independiente y se define como:
$$
VIF_i = \frac{1}{1 - R^2_{-i}}.
$$

Donde $R^2_{-i}$ es el coeficiente de determinación del modelo de regresión lineal que se ajusta a la variable $i$ como función de todas las demás variables independientes. Un VIF mayor a $10$ indica una alta multicolinealidad y sugiere que la variable $i$ puede ser redundante en el modelo. Lo recomendable es tener un VIF menor a $5$.

El críterio AIC (Akaike Information Criterion) es una medida que se utiliza para comparar modelos estadísticos. Se basa en la verosimilitud del modelo y penaliza la complejidad del modelo (número de parámetros). El AIC se define como:
$$
AIC = -2 \log(L) + 2k.
$$
Donde $L$ es la verosimilitud del modelo y $k$ es el número de parámetros en el modelo. Un AIC más bajo indica un mejor ajuste del modelo a los datos, teniendo en cuenta la complejidad del modelo. Al comparar varios modelos, se selecciona el que tiene el AIC más bajo. Un críterio simi;ar es el BIC (Bayesian Information Criterion), que penaliza más fuertemente la complejidad del modelo, se define como:
$$
BIC = -2 \log(L) + k \log(n).
$$

Donde igualmente $L$ es la verosimilitud del modelo, $k$ es el número de parámetros en el modelo y $n$ es el número de observaciones. Un BIC más bajo también indica un mejor ajuste del modelo a los datos, dada la complejidad del modelo y el número de observaciones.

Para ilustar estos ejemplos, se simularan 200 datos y 3 variables relacionadas con nuestra variable dependiente, 2 sin ninguna relación y 2 más con relación pero altamente correlacionadas entre sí. Se ajustarán modelos de regresión lineal múltiple y se calcularán los VIF y AIC para cada modelo.

```{r}
#| echo: false
#| warning: false
#| tbl-cap: "Ajuste de los Modelos"
#| label: tbl-modelos_ejemplos

library(MASS)

# Simulación de datos
set.seed(123)
n <- 200
x1 <- rnorm(n, -5, 23)
x2 <- rnorm(n, 3, 2)
x3 <- rnorm(n, 10, 24)

x4 <- rnorm(n, 5, 2)
x5 <- rnorm(n, 3, 2)

corr.x6.x7 <- 0.95
x.6.7 <- mvrnorm(n, mu = c(0, 0), Sigma = matrix(c(4, corr.x6.x7 * 2*4, corr.x6.x7* 2*4, 16), nrow = 2))

x6 <- x.6.7[, 1]
x7 <- x.6.7[, 2]

epsilon = rnorm(n, 0, 1)

betas.ejem = c(6, 2.456, -3, -5, 0.23, 0.45)

y <- betas.ejem[1] + betas.ejem[2]*x1 + betas.ejem[3]*x2 + betas.ejem[4]*x3 + betas.ejem[5]*x6 + betas.ejem[6]*x7 + epsilon

datos.ejemplo = data.frame(y, x1, x2, x3, x4, x5, x6, x7)

# Ajuste de modelos
mod_completo <- lm(y ~ ., data = datos.ejemplo)
mod_relevantes <- lm(y ~ x1 + x2 + x3 + x6 + x7, data = datos.ejemplo)
mod_no_corr_falses <- lm(y ~ x1 + x2 + x3 + x4 + x5, data = datos.ejemplo)
mod_no_corr_no_falses <- lm(y ~ x1 + x2 + x3, data = datos.ejemplo)
mod_corr_falsas_no_rele <- lm(y ~ x4 + x5 + x6 + x7, data = datos.ejemplo)

modelos <- list(
    "Modelo Completo" = mod_completo,
    "Modelo Efectos" = mod_relevantes,
    "Modelo No Correlacionados No Efectos" = mod_no_corr_falses,
    "Modelo No Correlacionados Efectos" = mod_no_corr_no_falses,
    "Modelo Correlacionados No Efectos No Relevantes" = mod_corr_falsas_no_rele
)

modelos_vif <- lapply(modelos, function(modelo) {
    vif(modelo)
})

modelsummary(
  modelos,
  statistic = c("conf.int",
                  "s.e. = {std.error}", 
                  "p = {p.value}"),
    stars = T
)
```

```{r}
#| fig-cap: "VIF para los modelos ajustados."
#| fig-subcap:
#|   -  "Modelo Completo"
#|   -  "Modelo Efectos"
#|   -  "Modelo No Correlacionados No Efectos"
#|   -  "Modelo No Correlacionados Efectos"
#|   -  "Modelo Correlacionados No Efectos No Relevantes"
#| label: fig-vif-ejemplo
#| layout: [[50, 50], [50, 50], [-25, 50, -25]]

# Crear un gráfico por cada modelo
vif_plot <- function(modelo, modelo_name) {
    data.frame(
        Variable = names(vif(modelo)),
        VIF = vif(modelo)
    ) %>%
    ggplot(aes(x = reorder(Variable, -VIF), y = VIF)) +
    geom_bar(stat = "identity", fill = "steelblue") +
    coord_flip() +
    labs(title = paste("VIF para el modelo:", modelo_name),
         x = "Variable",
         y = "VIF") +
    theme_minimal()
}


# Graficos
for (i in 1:length(modelos)) {
    modelo_name <- names(modelos)[i]
    modelo <- modelos[[i]]
    
    print(vif_plot(modelo, modelo_name))
}
```
La codificación para los modelos es la siguiente:

* **Efectos**: Contiene las variables que se relacionan con nuestro regresor pero no están correlacionadas entre sí (variables `x1`, `x2` y `x3`)

* **Correlacionados**: Contiene las variables que se relacionan con nuestro regresor y están correlacionadas entre sí (variables `x6` y `x7`)

* **No Relevantes**: Contiene las variables que no tienen relación con nuestro regresor y no están correlacionadas entre sí (variables `x4` y `x5`).

Su negación es lo opuesto. Como se ve en la tabla @tbl-modelos_ejemplos, el modelo Completo tiene un AIC de $551.5$, el modelo Efectos tiene un AIC de $547.7$ y contiene las variables relevantes que son menos, por lo cual su AIC es menor y dado que no tiene variables inecesarias eso se refleja en la verosimilitud del modelo. Los demás modelos tienen un AIC y BIC mucho mayor.

En la @fig-vif-ejemplo se puede ver que los modelos que contienen a las variables correlacionadas entre sí (modelos Correlacionados y Completo) tienen un VIF mayor a $10$, lo que indica que hay multicolinealidad en el modelo. En cambio, los modelos que no las contienen su VIF es de 1, dado que se simulaton variables que no están correlacionadas entre sí.

De esta manera podemos ver que la utilidad del VIF es detectar la multicolinealidad entre las variables y el AIC nos ayuda a seleccionar el mejor modelo entre varios modelos candidatos, teniendo en cuenta tanto el ajuste del modelo como su complejidad.

# Análisis de Datos.

## Variables

Tenemos un conjunto de datos que contiene información sobre la esperanza de vida en diferentes países y años. El conjunto de datos incluye las siguientes variables:

<style>
    table {
        width: 100%;
        border-collapse: collapse;
        margin: 20px 0;
        font-family: Arial, sans-serif;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    }
    th, td {
        padding: 12px 15px;
        text-align: left;
        border: 1px solid #ddd;
    }
    th {
        background-color: #4CAF50;
        color: white;
        font-weight: bold;
    }
        tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:hover {
        background-color: #ddd;
    }
</style>

<table>
    <thead>
        <tr>
            <th>Variable</th>
            <th>Descripción</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Country</td>
            <td>Categórica ($193$). Nombre del País.</td>
        </tr>
        <tr>
            <td>Year</td>
            <td>Númerica Discreta ($2000-2015$). Año.</td>
        </tr>
        <tr>
            <td>Status</td>
            <td>Categórica ($2$). Estado de Desarrollo del País.</td>
        </tr>
        <tr>
            <td>Life_expectancy</td>
            <td>Numérica Continua ($6.30-89$). Esperanza de Vida.</td>
        </tr>
        <tr>
            <td>Adult_Mortality</td>
            <td>Numérica Discreta ($1-723$). Tasa de Mortalidad en personas de 15 a 60 años por cada 1000 habitantes (ambos sexos).</td>
        </tr>
        <tr>
            <td>infant_deaths</td>
            <td>Numérica Discreta ($1-1800$). Tasa de Mortalidad infantil por cada 1000 habitantes.</td>
        </tr>
        <tr>
            <td>Alcohol</td>
            <td>Numérica Continua ($0.01-17.87$). Consumo de alcohol puro en litros per capita en mayores de 15 años.</td>
        </tr>
        <tr>
            <td>percentage_expenditure</td>
            <td>Numérica Continua ($0-19479.912$). Proporción del Producto Interno Bruto (PIB) per cápita de un país que se destina al gasto en salud.</td>
        </tr>
        <tr>
            <td>Hepatitis.B</td>
            <td>Numérica Continua ($1-99$). Porcentaje de Inmunización a Hepatitis B en infantes de $\leq1$ año.</td>
        </tr>
        <tr>
            <td>Measles</td>
            <td>Numérica Continua ($0-360.2$). Número de casos reportados de Rubeola por cada 1000 habitantes.</td>
        </tr>
        <tr>
            <td>BMI</td>
            <td>Númerica Continua ($1-87.30$). Promedio poblacional del Índice de Masa Corporal.</td>
        </tr>
        <tr>
            <td>U05_deaths</td>
            <td>Numérica Discreta ($0-2500$). Número de Muertes de Menores de 5 años por cada 1000 habitantes</td>
        </tr>
        <tr>
            <td>Polio</td>
            <td>Numérica Continua ($3-99$). Porcentaje de Inmunización a Polio en infantes de $\leq1$ año.</td>
        </tr>
        <tr>
            <td>Total_expenditure</td>
            <td> Numérica Continua ($0.370-17.600$). Proporción del gasto total del gobierno que se destina a la salud.</td>
        </tr>
        <tr>
            <td>Diphtheria</td>
            <td>Numérica Continua ($2-99$). Porcentaje de Inmunización a Difteria, Tétanos y Tosferina en infantes de $\leq1$ año.</td>
        </tr>
        <tr>
            <td>HIV.AIDS</td>
            <td>Númerica Continua ($0.1-50.6$). Tasa de mortalidad de niños menores de 1 año debido a VIH/SIDA</td>
        </tr>
        <tr>
            <td>GDP</td>
            <td>Númerica Continua ($1.68-119172.74$). Producto Interno Bruto per cápita en USD.</td>
        </tr>
        <tr>
            <td>Population</td>
            <td>Númerica Discreta ($3.400(10)^1 -1.294(10)^9$). Población del País.</td>
        </tr>
        <tr>
            <td>thinness._1to19years</td>
            <td>Numérica Continua ($0.1-27.7$). Proporción de delgadez entre niños y adolescentes de 10 a 19 años.</td>
        </tr>
        <tr>
            <td>thinness_5to.years</td>
            <td>Numérica Continua ($0.1-28.6$). Proporción de delgadez entre niños de 5 a 9 años.</td>
        </tr>
        <tr>
            <td>Income_composition_of_resources</td>
            <td>Numérica Continua ($0.1-0.948$). Índice de Desarrollo Humano en términos de la composición del ingreso de los recursos. </td>
        </tr>
        <tr>
            <td>Schooling</td>
            <td>Numérica Continua ($0-20.7$). Número de Años de Escolaridad.</td>
        </tr>
    </tbody>
</table>

    Nota: Las variables categóricas tienen entre paréntesis el número de categorías que tienen. Las variables numéricas discretas tienen entre paréntesis el rango de su valor en los datos.

## Análisis Exploratorio

Tenemos un total de `r ncol(datos)` variables y `r nrow(datos)` observaciones. De estas tenemos `r length(unique(datos$Country))` países distintos y `r length(unique(datos$Year))` años de datos.

### Resumen de los datos.

```{r}
#| tbl-cap: "Resumen de los datos"
#| label: tbl-resumen
#| warning: false

datasummary_skim(datos,
                 title = "",
                 fmt = 2,
                 output_options = list(kable_styling = list(full_width = F, position = "left")))

```

Como se observa en la @tbl-resumen, la mayoría de las variables tienen datos faltantes con un total de `r sum(is.na(datos))` datos faltantes. La variable con el mayor número de datos faltantes es "`r names(datos)[which.max(colSums(is.na(datos)))]`" con `r max(colSums(is.na(datos)))`, sus patrones y tratamiento se verá más adelante (véase @sec-missingdata). Hay variables que son continuas pero que no cubren un rango muy amplio y repiten muchos de sus valores. En general la mayoría de variables tienen una distribución sesgada como se observa en la última columna de la tabla.

Algo a notar es que hay variables con escalas extremadamente altas como son las que se relacionan con el PIB y la población. Esto puede afectar el análisis de regresión, por lo que se pueden estandarizar o utilizar alguna transformación que preserve su orden cómo lo es el logaritmo. Dado que algunas o casi todas de estas variables tienen valores $0$, es más factible normalizar las variables que aplicarles el logaritmo, por lo que para el análisis de regresión se normalizarán las variables que tengan un rango muy amplio.


### Correlación entre variables.

```{r}
#| fig-cap: "Correlación entre variables numéricas."
#| label: fig-correlacion

# Solo numericas
corr_datos <- datos %>%
    dplyr::select(-c(Country, Status)) %>%
    drop_na() %>%
    cor() %>%
    round(2) %>%
    as.data.frame() %>%
    rownames_to_column("Variable") %>%
    pivot_longer(cols = -Variable, names_to = "Variable2", values_to = "Correlacion")

p <- ggplot(corr_datos, aes(x = Variable, y = Variable2, fill = Correlacion)) +
    geom_tile() +
    scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, limit = c(-1, 1), name = "Correlación") +
    theme_minimal() +
    labs(title = "",
         x = "",
         y = "") +
    theme(axis.text.x = element_text(angle = 65, hjust = 1))

ggplotly(p)
```

En la @fig-correlacion se presenta la correlación entre las variables numéricas. La mayoría de las variables presentan correlación entre ellas baja, sin embargo existen algunas con una alta correlación (definida como $|\rho| \geq 0.5$) como son:

- `Percentage_expenditure` y `GDP` ($0.96$).
- `Population` y `infant_deaths` ($0.67$).
- `U05_deaths` y `infant_deaths` ($1$).
- `BMI` y `thinness._1to19years` ($-0.55$).
- `Hepatitis.B` y `Diphtheria` ($0.59$).
- `Adult.Mortality` y `HIV.AIDS` ($0.55$).
- `Alcohol` y `Income_composition_of_resources` ($-0.56$).
- `BMI` y `Income_composition_of_resources` ($0.51$).
- `Measles` y `Infant_deaths` ($0.53$).
- `Polio` y `Diphtheria` ($0.61$).
- `Alcohol` y `Schooling` ($0.62$).
- `Income_composition_of_resources` y `Schooling` ($0.78$).
- `BMI` y `Schooling` ($0.55$).
- `thinness._1to19years` y `thinness_5to.years` ($0.93$).
- `BMI` y `thinness_5to.years` ($-0.55$).
- `Measles` y `U05_deaths` ($0.52$).
- `Population` y `U05_deaths` ($0.66$)

Esta alta correlación genera un problema de colinealidad, lo que puede afectar el análisis de regresión. Para evitar esto, se procederá a seleccionar a una de dos variables donde la correlación sea mayor a $0.9$, dado que visualmente estás parecen si tener una relación lineal entre ellas. De hecho en el caso de `U05_deaths` y `infant_deaths` la correlación es de $1$ y es posible explicarlo dada que su definición es similar, por lo que se eliminará `infant_deaths` dado que tiene menor variabilidad (veáse  @tbl-resumen). Para `Percentage_expenditure` y `GDP` se seleccionará `Percentage_expenditure` dado que no tiene valores faltantes y su definición hace que sea más viable como predictor de la esperanza de vida que el `GDP`, además que es función de este último. 

Para `thinness._1to19years` y `thinness_5to.years`, se eligirá `thinness._1to19years` dado que su definición nos habla de un sector de la población no considerado en las otras variables (ya tenemos la mortalidad en adultos y la mortalidad infantil) y ambas tienen una estructura de correlación prácticamente igual con el resto de variables.

En resumen, se eliminarán las siguientes variables para el análisis de regresión:

- `infant_deaths`
- `GDP`
- `thinness_5to.years`

Las demás variables se dejarán y se evaluará su efecto usando el factor de inflación de variancia (VIF) para ver si afectan el modelo de regresión.

### Visualización de Datos.

Veremos la relación de las variables con la esperanza de vida. Para esto, graficaremos la esperanza de vida contra cada una de las variables numéricas y categóricas.

```{r}
#| warning: false
#| label: fig-vida1
#| fig-cap: "Relación de la Esperanza de Vida con otras variables (parte 1)."
#| fig-subcap:
#|   - "Esperanza de Vida vs Estado de Desarrollo."
#|   - "Esperanza de Vida vs Año."
#|   - "Esperanza de Vida vs Tasa de Mortalidad en Adultos y  Estado de Desarrollo."
#|   - "Esperanza de Vida vs Tasa de Mortalidad Infantil y Estado de Desarrollo."
#|   - "Esperanza de Vida vs Consumo de Alcohol y Estado de Desarrollo."
#|   - "Esperanza de Vida vs PIB per cápita destinado a la salud (log10) y Estado de Desarrollo."
#| layout: [[50, 50], [50, 50], [50, 50]]

datos %>%
    ggplot(aes(x = Status, y = Life_expectancy)) +
    geom_violin( aes(fill = Status), alpha = 0.45) +
    geom_boxplot(alpha = 0.25, width = 0.1, outlier.color = "red") +
    labs(title = "",
         x = "Estado de Desarrollo",
         y = "Esperanza de Vida",
         fill = "Estado de Desarrollo"
         ) +
    guides(fill = F) +
    theme_minimal() 

datos %>%
    ggplot(aes(x = as.factor(Year), y = Life_expectancy)) +
    geom_violin( aes(fill = as.factor(Year)), alpha = 0.45) +
    geom_boxplot(alpha = 0.25, width = 0.1, outlier.color = "red") +
    labs(title = "",
         x = "Año",
         y = "Esperanza de Vida",
         fill = "Año"
         ) +
    guides(fill = F) +
    theme_minimal()

datos %>%
    ggplot(aes(x = Adult_Mortality, y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Tasa de Mortalidad en Adultos",
         y = "Esperanza de Vida") +
    theme_minimal() + 
    theme(legend.position = c(0.8, 0.95))

datos %>%
    ggplot(aes(x = infant_deaths, y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Tasa de Mortalidad Infantil",
         y = "Esperanza de Vida") +
    theme_minimal() +
    theme(legend.position = c(0.8, 0.95))


datos %>%
    ggplot(aes(x = Alcohol, y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Consumo de Alcohol",
         y = "Esperanza de Vida") +
    theme_minimal() +
    theme(legend.position = c(0.85, 0.25))

datos %>%
    ggplot(aes(x = log10(percentage_expenditure), y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = " PIB per cápita destinado a la salud (log10)",
         y = " Esperanza de Vida") +
    theme_minimal() +
    theme(legend.position = c(0.85, 0.25))
```

En esta primera parte podemos ver que la clasificación de un país como desarrollado o en vías de desarrollo parece tener un gran efecto en la distribución de la esperanza de vida. Los países desarrollados tienen una esperanza de vida mucho mayor que los países en vías de desarrollo. Esto se puede ver en la @fig-vida1-1, donde la esperanza de vida es significativamente mayor en los países desarrollados. El año también parece influir positivamente en la esperanza de vida, dado que se denota una clara tendencia a aumentar la esperanza de vida a lo largo del tiempo (@fig-vida1-2). 

Hay variables que no parecen tener una relación lineal con la esperanza de vida, como lo son la mortalidad en adultos, la mortalidad infantil y el consumo de alcohol (@fig-vida1-3, @fig-vida1-4 y @fig-vida1-5). Sin embargo, la mortalidad infantil y en adultos parece tener una relación negativa con la esperanza de vida, lo que es lógico dado que a mayor mortalidad, menor esperanza de vida. El consumo de alcohol parece tener una relación positiva muy débil con la esperanza de vida. La proporción del PIB per cápita destinado a la salud también parece tener una relación positiva con la esperanza de vida (@fig-vida1-6).

Dado que los países desarrollados tiene un fuerte efecto a simple vista, se estratificaron los gráficos por estado de desarrollo y como se ve en la @fig-vida1, los países desarrollados tienen un valor más alto en las variables "buenas" y bajo en las "malas" como la mortalidad infantil y en adultos. Esto sugiere que los países desarrollados tienen un mejor sistema de salud y una mejor calidad de vida en general. Sin embargo, hay algunos países en vías de desarrollo que tienen valores similares o mejores en ciertas variables.

```{r}
#| warning: false
#| label: fig-vida2
#| fig-cap: "Relación de la Esperanza de Vida con otras variables (parte 2)."
#| fig-subcap:
#|   - "Esperanza de Vida vs Immunización a Hepatitis B y Estado de Desarrollo."
#|   - "Esperanza de Vida vs Número de casos reportados de Rubeola (log10) y Estado de Desarrollo."
#|   - "Esperanza de Vida vs Índice de Masa Corporal y Estado de Desarrollo."
#|   - "Esperanza de Vida vs Número de Muertes de Menores de 5 años (log10) y Estado de Desarrollo."
#|   - "Esperanza de Vida vs Inmunización a Polio y Estado de Desarrollo."
#|   - "Esperanza de Vida vs Proporción del gasto total del gobierno que se destina a la salud y Estado de Desarrollo."
#| layout: [[50, 50], [50, 50], [50, 50]]

datos %>%
    ggplot(aes(x = Hepatitis.B, y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Porcentaje de Inmunización a Hepatitis B",
         y = "Esperanza de Vida") +
    theme_minimal()

datos %>%
    ggplot(aes(x = log10(Measles), y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Número de casos reportados de Rubeola (log10)",
         y = "Esperanza de Vida") +
    theme_minimal()

datos %>%
    ggplot(aes(x = BMI, y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Índice de Masa Corporal", y = "Esperanza de Vida") +
    theme_minimal() +
    theme(legend.position = c(0.85, 0.25))

datos %>%
    ggplot(aes(x = log10(U05_deaths), y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Número de Muertes de Menores de 5 años (log10)",
         y = "Esperanza de Vida") +
    theme_minimal() +
    theme(legend.position = c(0.85, 0.93))

datos %>%
    ggplot(aes(x = Polio, y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Porcentaje de Inmunización a Polio",
         y = "Esperanza de Vida") +
    theme_minimal() +
    theme(legend.position = c(0.3, 0.95))

datos %>%
    ggplot(aes(x = Total_expenditure, y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Proporción del gasto total del gobierno que se destina a la salud",
         y = "Esperanza de Vida") +
    theme_minimal()
```

En la @fig-vida2 se observa que la inmunización a Hepatitis B y Rubeola no parecen tener una relación con la esperanza de vida, dado que no se observa una tendencia clara en los gráficos (@fig-vida2-1 y @fig-vida2-2). En cambio el índice de masa corporal parece tener una relación positiva con la esperanza de vida y tiene una relación más lineal que las variables pasadas (@fig-vida2-3). Cómo ya se había observado la mortalidad infantil esta muy correlacionada con el número de muertes de menores de 5 años, por lo que no se espera que la relación con la esperanza de vida sea diferente y esto mismo se observa en la @fig-vida2-4.  

La inmunización a Polio y el porcentaje del gasto total del gobierno que se destina a la salud parecen tener una relación positiva con la esperanza de vida (@fig-vida2-5 y @fig-vida2-6). Sin embargo, la inmunización a Polio parece tener una relación más lineal que el gasto en salud, lo que sugiere que la inmunización a Polio puede ser un mejor predictor de la esperanza de vida que el gasto en salud. Aunque en ambos casos la relación linal es algo pobre.

```{r}
#| warning: false
#| label: fig-vida3
#| fig-cap: "Relación de la Esperanza de Vida con otras variables (parte 3)."
#| fig-subcap:
#|   - "Esperanza de Vida vs Inmunización a Difteria, Tétanos y Tosferina y Estado de Desarrollo."
#|   - "Esperanza de Vida vs Tasa de mortalidad de niños menores de 1 año debido a VIH/SIDA y Estado de Desarrollo."
#|   - "Esperanza de Vida vs PIB per cápita (log10) y Estado de Desarrollo."
#|   - "Esperanza de Vida vs Población del País (log10) y Estado de Desarrollo."
#|   - "Esperanza de Vida vs Proporción de delgadez entre niños y adolescentes de 10 a 19 años y Estado de Desarrollo."
#|   - "Esperanza de Vida vs Proporción de delgadez entre niños de 5 a 9 años y Estado de Desarrollo."
#|   - "Esperanza de Vida vs Índice de Ingreso del IDH y Estado de Desarrollo."
#|   - "Esperanza de Vida vs Número de Años de Escolaridad y Estado de Desarrollo."
#| layout: [[50, 50], [50, 50], [50, 50], [50, 50]]

datos %>%
    ggplot(aes(x = Diphtheria, y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Porcentaje de Inmunización a Difteria, Tétanos y Tosferina",
         y = "Esperanza de Vida") +
    theme_minimal() +
    theme(legend.position = c(0.35, 0.95))


datos %>%
    ggplot(aes(x = HIV.AIDS, y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Tasa de mortalidad de niños menores de 1 año debido a VIH/SIDA",
         y = "Esperanza de Vida") +
    theme_minimal() +
    theme(legend.position = c(0.85, 0.95))

datos %>%
    ggplot(aes(x = log10(GDP), y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Producto Interno Bruto per cápita en USD (log10)",
         y = "Esperanza de Vida") +
    theme_minimal() +
    theme(legend.position = c(0.85, 0.15))

datos %>%
    ggplot(aes(x = log10(Population), y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Población del País (log10)",
         y = "Esperanza de Vida") +
    theme_minimal() +
    theme(legend.position = c(0.1, 0.15))

datos %>%
    ggplot(aes(x = thinness._1to19years, y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Proporción de delgadez entre niños y adolescentes de 10 a 19 años",
         y = "Esperanza de Vida") +
    theme_minimal() +
    theme(legend.position = c(0.85, 0.9))

datos %>%
    ggplot(aes(x = thinness_5to.years, y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Proporción de delgadez entre niños de 5 a 9 años",
         y = "Esperanza de Vida") +
    theme_minimal() +
    theme(legend.position = c(0.85, 0.9))

datos %>%
    ggplot(aes(x = Income_composition_of_resources, y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Índice de Ingreso del Índice de Desarrollo Humano",
         y = "Esperanza de Vida") +
    theme_minimal() +
    theme(legend.position = c(0.85, 0.2))

datos %>%
    ggplot(aes(x = Schooling, y = Life_expectancy, colour = Status)) +
    geom_point(alpha = 0.5) +
    geom_smooth(method = "lm", color = "black", se = T, linewidth = 0.75) +
    labs(title = "",
         x = "Número de Años de Escolaridad",
         y = "Esperanza de Vida") +
    theme_minimal() +
    theme(legend.position = c(0.85, 0.2))
```


La inmunización a Difteria, Tétanos y Tosferina tiene una relación muy similar a la de la Polio con la esperanza de vida (@fig-vida3-1). La mortalidad por VIH/SIDA parece tener una relación no lineal y del tipo exponencial con la esperanza de vida (@fig-vida3-2). Esto sugiere que a medida que aumenta la mortalidad por VIH/SIDA, la esperanza de vida disminuye de manera exponencial. El PIB per cápita parece tener una relación positiva con la esperanza de vida (@fig-vida3-3) y la población parece no tener ninguna relación con la esperanza de vida (@fig-vida3-4). Como igual ya se había mencionado, la delgadez en niños y adolescentes tienen una distribución prácticamente idéntica y esto se ve claro al ver como se relacionan con la esperanza de vida que es la misma entre ambas (@fig-vida3-5 y @fig-vida3-6). 

El índice de ingreso del Índice de Desarrollo Humano y el número de años de escolaridad parecen tener una relación positiva con la esperanza de vida (@fig-vida3-7 y @fig-vida3-8) y mucho más lineal que todas las variables pasadas. Esto sugiere que a medida que aumenta el índice de ingreso del Índice de Desarrollo Humano y el número de años de escolaridad, la esperanza de vida también aumenta. Esto es lógico dado que a mayor educación y mayores ingresos, se espera que la calidad de vida y el acceso a servicios de salud sean mejores.


### Datos Faltantes. {#sec-missingdata}

```{r}
#| fig-cap: "Datos Faltantes por Variable"
#| label: fig-faltantes

datos <- datos %>%
    dplyr::select(-c(infant_deaths, GDP, thinness_5to.years))

faltantes_df <- datos %>%
    summarise(across(everything(), ~ sum(is.na(.)))) %>%
    pivot_longer(cols = everything(), names_to = "Variable", values_to = "Faltantes") %>%
    mutate(Variable = factor(Variable, levels = names(datos)))


p <- ggplot(faltantes_df, aes(x = Variable, y = Faltantes)) +
    geom_bar(stat = "identity", fill = "steelblue") +
    geom_text(aes(label = Faltantes), vjust = 0.25, size = 3, hjust = -0.5) +
    ylim(0, 700) +
    coord_flip() +
    labs(title = "",
         x = "",
         y = "Número de Datos Faltantes") +
    theme_minimal()

p
```

```{r}
#| fig-cap: "Porcentaje de Datos Faltantes por Variable"
#| label: fig-faltantes_propo

# Porcentaje de datos faltantes
faltantes_df <- datos %>%
    summarise(across(everything(), ~ sum(is.na(.)))) %>%
    pivot_longer(cols = everything(), names_to = "Variable", values_to = "Faltantes") %>%
    mutate(Variable = factor(Variable, levels = names(datos)),
           Porcentaje = (Faltantes / nrow(datos)) * 100)


p <- ggplot(faltantes_df, aes(x = Variable, y = Porcentaje)) +
    geom_bar(stat = "identity", fill = "steelblue") +
    geom_text(aes(label = round(Porcentaje, 2)), vjust = 0.25, size = 3, hjust = -0.5) +
    geom_hline(yintercept = 15, color = "red", linetype = "dashed") +
    ylim(0, 25) +
    coord_flip() +
    labs(title = "",
         x = "",
         y = "Porcentaje de Datos Faltantes") +
    theme_minimal()
p
```

En las @fig-faltantes y @fig-faltantes_propo se muestran el número y el procentaje de datos faltantes respectivamente por variable. `Population`, `Hepatitis.B`, `Total_expenditure`, `Alcohol`, `Schooling` y `Income_composition_of_resources` son las variables que tienen mayor cantidad de datos faltantes sumando un total de `r 163 + 167 + 652 + 226 + 553 + 194` datos faltantes que correspnden al `r round(1955/2563, 4) * 100`% de los datos faltantes totales (2563). Sin emabargo, aún se puede considerar un porcentaje bajo de datos faltantes, en casi todas las variables. Por ello se procederá a imputar los valores faltantes usando la libreria `mice` de `R` que utiliza el método de imputación por regresión múltiple. Este método es uno de los más utilizados y recomendados para la imputación de datos faltantes, ya que utiliza la información de las otras variables para predecir los valores faltantes y parece ser la mejor opción para este caso.

Los valores faltantes de nuestra variable dependiente (esperanza de vida) no se imputarán y mas bien sus valores se predecirán usando el modelo de regresión lineal que se ajuste a los datos.

#### Patrón de Datos Faltantes.

Antes de proceder a la imputación de los datos faltantes, es importante visualizar el patrón de los datos faltantes. Esto nos ayudará a entender si los datos faltantes son aleatorios o si hay algún patrón en ellos. Para esto se usará la función `rm.pattern` de la librería `mice` con ayuda de una paqueteria auxiliar para mejorar su presentación gráfica (`ggmice`).

```{r}
#| fig-cap: "Patrón de Datos Faltantes"
#| label: fig-patron_faltantes
#| fig-width: 10
#| fig-height: 10

# Seleccionamos las variables con datos faltantes
datos_missing <- datos[, colSums(is.na(datos)) > 0]

p <- plot_pattern(datos_missing,
             rotate = T,
             square = F)
p 
```

Se puede observar que si parecieran existir patrones en los datos faltantes. En la @fig-patron_faltantes se observa que hay un patrón de datos faltantes en prácticamente todas las variables en pequeños subconjuntos, pero igual hay algunos patrones que parecen más aleatorios. Esto sugiere que los datos faltantes no son completamente aleatorios y que puede haber algún patrón en ellos. Sin embargo, dado que la mayoría de los datos faltantes son pocos, se procederá a imputar los datos faltantes usando el método de regresión múltiple. Y además es muy probable que estos patrones surgan de países donde no tenemos los datos de varías variable en todos los años. Si esto es cierto, la imputación de los datos faltantes no debería ser tan eficaz dado que serían MNAR (Missing not at random). Sin embargo, el algoritmo de la librería se ha mostrado robusto a datos MNAR y se espera que la imputación sea buena.

#### Imputación de Datos Faltantes.

Dados algunos problemas computacionales, la matriz de predictores se construyó manualmente. Esto se hizo utilizando la matriz de correlación entre las variables y se uso un umbral ($|\rho| \geq 0.26$) a base de error y acierto para seleccionar las variables que se usarían como predictores. Este umbral se eligió para evitar la multicolinealidad entre las variables y se usó un umbral bajo para evitar perder información.

```{r}    
#| warning: false
#| code-fold: show

y <- datos %>%
    dplyr::select(Life_expectancy) %>%
    as.vector() %>%
    unlist() %>%
    unname()

covariables <- datos %>%
    dplyr::select(-c(Life_expectancy, Country, Status)) %>%
    mutate(across(everything(), ~ as.numeric(.))) 

cor_mat <- cor(covariables, use = "pairwise.complete.obs")

threshold <- 0.26

# Matriz booleana: TRUE si abs(correlación) > threshold y no es la diagonal
pred_matrix <- abs(cor_mat) > threshold
diag(pred_matrix) <- FALSE  # evitar que una variable se prediga a sí misma

# Convertir a enteros (0/1)
predictorMatrix <- pred_matrix * 1


# Imputación de datos faltantes
imp <- mice(covariables,
            method = "pmm",
            predictorMatrix = predictorMatrix,
            m = 5,
            maxit = 50,
            seed = 1234,
            print=F
            )
```

##### Evaluación de la imputación.

```{r}
#| fig-cap: "Convergencia de la imputación."
#| fig-subcap:
#|    - "Convergencia de la imputación para Adult_Mortality, Alcohol y Hepatitis.B."
#|    - "Convergencia de la imputación para BMI, Polio y Total Expenditure."
#|    - "Convergencia de la imputación para Diphtheria, Population, Thinnes._1to19years."
#|    - "Convergencia de la imputación para Schooling e Income_compositon_of_resources."
#| label: fig-eval_imputacion
#| layout: [[50, 50], [50, 50], [50, 50]]

# Evaluación de la imputación
plot(imp, main = "")
```

En @fig-eval_imputacion se observa la convergencia de la imputación para las variables `Adult_Mortality`, `Alcohol`, `Hepatitis.B`, `BMI`, `Polio`, `Total_expenditure`, `Diphtheria`, `Population`, `thinness._1to19years`, `Schooling` e `Income_composition_of_resources`. Se observa que la imputación converge y que los valores imputados son razonables. Esto sugiere que la imputación fue exitosa y que los datos faltantes fueron imputados de manera adecuada.

Otra manera de verificar la consistencia de los datos imputados es ver la distribución de los datos imputados. Esto se puede hacer graficando la distribución de los datos imputados para cada variable. Esto nos ayudará a ver si los datos imputados son razonables y si siguen la misma distribución que los datos originales. En la @fig-distribucion_imputacion se observa esto y se puede ver que la mayoría de los datos imputados siguen la misma distribución que los datos originales, por lo cual se puede concluir que la imputación fue exitosa y podemos usar cualquier de los 5 conjuntos de datos imputados para el análisis posterior.

```{r}
#| fig-cap: "Distribución de los datos imputados."
#| fig-subcap:
#|   - "Distribución de datos imputados para Adult_Mortality."
#|   - "Distribución de datos imputados para Alcohol."
#|   - "Distribución de datos imputados para Hepatitis.B."
#|   - "Distribución de datos imputados para BMI."
#|   - "Distribución de datos imputados para Polio."
#|   - "Distribución de datos imputados para Total_expenditure."
#|   - "Distribución de datos imputados para Diphtheria."
#|   - "Distribución de datos imputados para Population."
#|   - "Distribución de datos imputados para thinness._1to19years."
#|   - "Distribución de datos imputados para Schooling."
#|   - "Distribución de datos imputados para Income_composition_of_resources."
#| label: fig-distribucion_imputacion
#| layout: [[50, 50], [50, 50], [50, 50], [50, 50], [50, 50], [-25, 50, -25]]

# Distribución de los datos imputados
ggmice(imp, aes(.imp, Adult_Mortality)) +
  geom_jitter(height = 0, width = 0.25) +
    geom_boxplot(width = 0.5, size = 1, alpha = 0.75, outlier.shape = NA) +
  labs(x = "Número de Imputación")

ggmice(imp, aes(.imp, Alcohol)) +
  geom_jitter(height = 0, width = 0.25) +
    geom_boxplot(width = 0.5, size = 1, alpha = 0.75, outlier.shape = NA) +
  labs(x = "Número de Imputación")

ggmice(imp, aes(.imp, Hepatitis.B)) +
  geom_jitter(height = 0, width = 0.25) +
    geom_boxplot(width = 0.5, size = 1, alpha = 0.75, outlier.shape = NA) +
  labs(x = "Número de Imputación")

ggmice(imp, aes(.imp, BMI)) +
  geom_jitter(height = 0, width = 0.25) +
    geom_boxplot(width = 0.5, size = 1, alpha = 0.75, outlier.shape = NA) +
  labs(x = "Número de Imputaciónr")

ggmice(imp, aes(.imp, Polio)) +
  geom_jitter(height = 0, width = 0.25) +
    geom_boxplot(width = 0.5, size = 1, alpha = 0.75, outlier.shape = NA) +
  labs(x = "Número de Imputación")

ggmice(imp, aes(.imp, Total_expenditure)) +
  geom_jitter(height = 0, width = 0.25) +
    geom_boxplot(width = 0.5, size = 1, alpha = 0.75, outlier.shape = NA) +
  labs(x = "Número de Imputación")

ggmice(imp, aes(.imp, Diphtheria)) +
  geom_jitter(height = 0, width = 0.25) +
    geom_boxplot(width = 0.5, size = 1, alpha = 0.75, outlier.shape = NA) +
  labs(x = "Número de Imputación")

ggmice(imp, aes(.imp, Population)) +
  geom_jitter(height = 0, width = 0.25) +
    geom_boxplot(width = 0.5, size = 1, alpha = 0.75, outlier.shape = NA) +
  labs(x = "Número de Imputación")

ggmice(imp, aes(.imp, thinness._1to19years)) +
  geom_jitter(height = 0, width = 0.25) +
    geom_boxplot(width = 0.5, size = 1, alpha = 0.75, outlier.shape = NA) +
  labs(x = "Número de Imputación")

ggmice(imp, aes(.imp, Schooling)) +
  geom_jitter(height = 0, width = 0.25) +
    geom_boxplot(width = 0.5, size = 1, alpha = 0.75, outlier.shape = NA) +
  labs(x = "Número de Imputación")

ggmice(imp, aes(.imp, Income_composition_of_resources)) +
  geom_jitter(height = 0, width = 0.25) +
    geom_boxplot(width = 0.5, size = 1, alpha = 0.75, outlier.shape = NA) +
  labs(x = "Número de Imputación")
```

## Modelo de Regresión Lineal.

Como se vio en el análisis exploratorio, todas las variables parecen tener una relación con la esperanza de vida de mayor o menor medida y con maoyr o menor linealidad. Por lo que se procederá a ajustar un modelo de regresión lineal múltiple con todas las variables y se evaluará su desempeño. Se usarán los métodos de *forward*, *backward* y *stepwise* para seleccionar el mejor modelo usando el criterio de información bayesinao (BIC) y se seleccionará el modelo con el menor BIC y/o complejidad cuando se comparen los modelos estimados.

### Modelo Completo.
```{r}
#| warning: false

imp_data <- complete(imp, 2)

imp_data <- imp_data %>%
    add_column(Status = datos$Status) %>%
    add_column(Life_expectancy = datos$Life_expectancy)

rows_to_predict <- which(is.na(imp_data$Life_expectancy))

models_data <- imp_data[-rows_to_predict, ]

data <- models_data %>%
    mutate(Status = as.factor(Status)) %>%
    mutate(Status = dplyr::recode(Status, "Developed" = 1, "Developing" = 0))
```

```{r}
#| code-fold: show
# Ajustar el modelo completo
modelo_completo <- lm(Life_expectancy ~ .,
                       data = data)
```

```{r}
#| tbl-cap: "Modelo Completo."
#| label: tbl-modelo_completo

f_row = tribble(
    ~term, ~model, ~statistic,
    
)

modelsummary(list( "Modelo Completo" = modelo_completo),
             fmt = fmt_decimal(9, 4),             
             statistic = c("conf.int",
                           "std.error", 
                           "statistic",
                           "p.value"),
             stars = T,
             shape = term ~ model + statistic             
             )

```

En la @tbl-modelo_completo se muestran algunos estadísticos importantes de nuestros parámetos estimados. Las variables con un efecto no significativo a un nivel de $\alpha = 0.05$ en la esperanza de vida para este modelo son: `Year`, `Alcohol`, `Hepatitis.B`, `Measles` y `Total_expenditure` dada la presencia de las demás variables.

El modelo es significativo con un $F =$ `r round(summary(modelo_completo)$fstatistic[1], 2)` con `r summary(modelo_completo)$fstatistic[2]` y `r summary(modelo_completo)$fstatistic[3]` grados de libertad y un $p$-valor de $< 2.2e-16$. El $R^2$ ajustado es de `r round(summary(modelo_completo)$adj.r.squared, 4)` lo que sugiere que el modelo es bueno. La interpretación del modelo se prosponda hasta la selección del mejor modelo.



### Modelo Forward.

```{r}
#| warning: false
#| code-fold: show

n = nrow(data)

# Usamos el criterio BIC
modelo_forward <- stepAIC(modelo_completo,
                        direction = "forward",
                        scope = list(lower = lm(Life_expectancy ~ 1, data = data),
                                     upper = modelo_completo),
                        k = log(n),
                        trace = 0)
```

```{r}
#| tbl-cap: "Modelo Forward."
#| label: tbl-modelo_forw

modelsummary(list( "Modelo Forward" = modelo_forward), 
             fmt = fmt_decimal(9, 4), statistic = c("conf.int",
                           "std.error", 
                           "statistic",
                           "p.value"),
             stars = T,
             shape = term ~ model + statistic
             )

```

El modelo forward es significativo con un $F =$ `r round(summary(modelo_forward)$fstatistic[1], 2)` con `r summary(modelo_forward)$fstatistic[2]` y `r summary(modelo_forward)$fstatistic[3]` grados de libertad y un $p$-valor de $< 2.2e-16$. El $R^2$ ajustado es de `r round(summary(modelo_forward)$adj.r.squared, 4)` lo que sugiere que el modelo es bueno. Y resulto ser el mismo modelo que el modelo completo.

### Modelo Backward.

```{r}
#| warning: false
#| code-fold: show


# Usamos el criterio BIC
modelo_backward <- stepAIC(modelo_completo,
                        direction = "backward",
                        scope = list(lower = lm(Life_expectancy ~ 1, data = data),
                                     upper = modelo_completo),
                        k = log(n),
                        trace = 0)
```

```{r}
#| tbl-cap: "Modelo Backward."
#| label: tbl-modelo_back

modelsummary(list( "Modelo Backward" = modelo_backward), 
             fmt = fmt_decimal(9, 4), statistic = c("conf.int",
                           "std.error", 
                           "statistic",
                           "p.value"),
             stars = T,
             shape = term ~ model + statistic
             )
```

El modelo backward es estadísticamente significativo con un $F =$ `r round(summary(modelo_backward)$fstatistic[1], 2)` y con `r summary(modelo_backward)$fstatistic[2]` y `r summary(modelo_backward)$fstatistic[3]` grados de libertad, su $p$-valor es $< 2.2e-16$. El $R^2$ ajustado es `r round(summary(modelo_backward)$adj.r.squared, 4)`. 

Es un modelo menos complejo que el modelo completo y el modelo forward y con valor de $R^2$ muy similar al de los otros y por tanto es un mejor modelo.

### Modelo Stepwise.

```{r}
#| warning: false
#| code-fold: show

# Usamos el criterio BIC
modelo_stepwise <- stepAIC(modelo_completo,
                        direction = "both",
                        scope = list(lower = lm(Life_expectancy ~ 1, data = data),
                                     upper = modelo_completo),
                        k = log(n),
                        trace = 0)
```

```{r}
#| tbl-cap: "Modelo Stepwise."
#| label: tbl-modelo_step

modelsummary(list( "Modelo Stepwise" = modelo_stepwise), 
             fmt = fmt_decimal(9, 4), statistic = c("conf.int",
                           "std.error", 
                           "statistic",
                           "p.value"),
             stars = T,
             shape = term ~ model + statistic
             )
```

Este último modelo es idéntico al anterior y con el mismo ajuste.


### Comparación de Modelos.

```{r}
#| warning: false
#| tbl-cap: "Comparación de Modelos."
#| label: tbl-modelos


modelos <- list(
    "Modelo Completo" = modelo_completo,
    "Modelo Forward" = modelo_forward,
    "Modelo Backward" = modelo_backward,
    "Modelo Stepwise" = modelo_stepwise
)

# Comparar los modelos
modelsummary(
    modelos,
    fmt = fmt_decimal(9, 4),
    statistic = c("conf.int",
                  "s.e. = {std.error}", 
                  "p = {p.value}"),
    stars = T)
```

En la @tbl-modelos se muestran los estadísticos de los modelos ajustados. Se observa que el modelo backward es el mejor modelo con un BIC de `r round(BIC(modelo_backward), 2)` y un $R^2$ ajustado de `r round(summary(modelo_backward)$adj.r.squared, 4)`. El modelo stepwise es el segundo mejor modelo con un BIC de `r round(BIC(modelo_stepwise), 2)` y un $R^2$ ajustado de `r round(summary(modelo_stepwise)$adj.r.squared, 4)`. El modelo forward es el tercer mejor modelo con un BIC de `r round(BIC(modelo_forward), 2)` y un $R^2$ ajustado de `r round(summary(modelo_forward)$adj.r.squared, 4)`. Y el modelo completo es el peor modelo con un BIC de `r round(BIC(modelo_completo), 2)` y un $R^2$ ajustado de `r round(summary(modelo_completo)$adj.r.squared, 4)`. Por lo que se puede concluir que el mejor modelo es el modelo backward.

Por lo que se puede apreciar que el modelo backward es el mejor modelo dado que es el más parsimonioso (10 parámetros), tiene un BIC/AIC más bajo que los demás modelos y con un valor de $R^2$ prácticamente idéntico al de los modelos más complejos.

## Modelo Ajustado.

El **modelo selccionado** es el siguiente:

`r paste0("Esperanza de Vida = ", round(coef(modelo_backward)[1], 4), " + ",  paste0( "(", round(coef(modelo_backward)[-1], 4), ") * ", names(coef(modelo_backward)[-1]), collapse = " + "))`

Este modelo nos indica que existen variables que aumentan el promedio de la esperanza de vida de la población en los países de nuestros datos. En particular `Income_composition_of_resources` nos indica que el factor de ingresos del índice de desarrollo humano tiene un efecto positivo en la esperanza de vida. Lo que es lógico pues a mayor ingreso, se espera que la calidad de vida y el acceso a servicios de salud sean mejores. 

`Schooling` tiene un efecto positivo en la esperanza de vida, lo que sugiere que a mayor educación, la esperanza de vida también aumenta. Esto es lógico dado que a mayor educación, se espera que la calidad de vida y el concimiento sobre salud sean mejores. 

`Diphtheria` tiene igualmente un efecto positivo en la esperanza de vida, lo que sugiere que a mayor inmunización a difteria, tétanos y tosferina, la esperanza de vida también aumenta. Esto es lógico dado que a mayor inmunización, se espera que la aparición de estas enfermedades sean menor en la población y aumente su esperanza de vida dado que pueden ser enfermedades altamente mortales sin los cuidados pertinentes. 

`Polio` también tiene un efecto positivo en la esperanza de vida, lo que es esperable dado que igualmente habla de la inmunización a una enfermedad que puede tener tasas de mortalidad alta.

`percentage_expenditure` es otra variable con un efecto positivo e indica que la inversión en salud tiene un efecto positivo en la esperanza de vida. Lo cual tiene toda la lógica del mundo pues esto beneficia a la población en general y a su calidad de vida.

`BMI` también tiene un efecto positvo aunque algo pequeño, Esto sugiere que un buen nivel de BMI aumenta la esperanza de vida, aunque no es tan claro si esto es así dado que el BMI es una variable que no distingue a personas con un BMI alto por sobrepeso u obesidad de aquellas que tienen un BMI alto por musculatura.

`Status` es la segunda variable con mayor efecto positivo en la esperanza de vida. Esto sugiere que los países desarrollados tienen una esperanza de vida mayor que los países en desarrollo. Lo cual es lo que se observa en general, dado que los países desarrollados tienen un mejor acceso a servicios de salud, más modernos y con personal mucho más capacitado.

Las variables con un efecto negativo se relacionan con tasas de mortalidad de distinto tipo como la mortalidad en adultos (`Adult_Mortality`), la mortalidad por VIH/SIDA en infantes (`HIV/AIDS`) y la muerte de menores de 5 años (`U05_deaths `).

### Evaluación del Modelo.

#### Factor de Inflación de Varianza (VIF).

Esta medida nos permite evaluar la multicolinealidad entre las variables independientes. Un VIF mayor a 5 indica que la variable tiene una alta colinealidad con las demás variables y por lo tanto no es recomendable incluirla en el modelo. Un VIF mayor a 10 indica que la variable tiene una colinealidad muy alta y es recomendable eliminarla del modelo.

```{r}
#| warning: false
#| fig-cap: "Factor de Inflación de Varianza (VIF)."
#| label: fig-vif
#| layout: [[-20, 60, -20]]

# Estimamos el VIF para el modelo backward
vif_backward <- vif(modelo_backward)
vif_backward <- as.data.frame(vif_backward)
vif_df <- vif_backward %>%
    rename(VIF = vif_backward) %>%
    arrange(desc(VIF))


vif_df <- vif_df %>%
    mutate(Variable =  row.names(vif_backward)) %>%
    mutate(VIF = round(VIF, 4))

# Barplots
ggplot(vif_df, aes(x = Variable, y = VIF)) +
    geom_bar(stat = "identity", fill = "steelblue") +
    geom_text(aes(label = round(VIF, 2)), vjust = 0.25, size = 3, hjust = -0.5) +
    ylim(0, 10) +
    coord_flip() +
    labs(title = "",
         x = "",
         y = "VIF") +
    theme_minimal()
```

Como podemos observar, nuestro modelo no parece presentar problemas de multicolinealidad dado que el VIF de todas las variables es menor a 5. Sin embargo, `percentage_expenditure` y `Adult_Mortality` tienen un VIF de 3.03 y 3.43 respectivamente, lo que sugiere que podrían tener una colinealidad leve o moderada con las demás variables, pero no es un problema grave. Por lo que se puede concluir que el modelo no presenta problemas de multicolinealidad y por lo tanto no es necesario eliminar ninguna variable del modelo.

#### Normalidad de los Residuos.

```{r}
#| warning: false
#| fig-cap: "Evaluación de la Normalidad de los Residuos."
#| fig-subcap:
#|    - "QQ-plot de los residuos del modelo."
#|    - "Histograma de los residuos del modelo."
#| label: fig-residuos
#| layout: [[50, 50]]
# Residuos del modelo
resdiduos <- modelo_backward$residuals

anderson <- ad.test(resdiduos)
kolmo <- ks.test(resdiduos, "pnorm", mean = mean(resdiduos), sd = sd(resdiduos))

# QQ-plot
ggplot(modelo_backward, aes(sample = .resid)) +
    geom_qq() +
    geom_qq_line() +
    labs(title = "",
         x = "Cuantiles Teóricos",
         y = "Cuantiles de los Residuos") +
    theme_minimal()

# Histograma
ggplot(modelo_backward, aes(x = .resid)) +
    geom_histogram(aes(y = ..density..), bins = 50, fill = "steelblue", alpha = 0.5) +
    geom_density(color = "red", size = 1) +
    labs(title = "",
         x = "Residuos",
         y = "Densidad") +
    theme_minimal()
```

Vemos el QQ-plot de los residuos en @fig-residuos-1 donde vemos claramente que las colas se alejan bastante de la distribución de quantiles de una normal. Esto se ve más claramente en el histograma de los residuos en @fig-residuos-2 donde se observa que la distribución de los residuos no tiene una forma de una distribución normal, dado que tienen colas más ligeras, algo que asemeja más a una distribución log-normal.

Por lo cual al menos visualmente no parece que se cumpla el supuesto de normalidad de los residuos. Para comprobar esta idea, se realizaron dos pruebas de normalidad: la prueba de Anderson-Darling y la prueba de Kolmogorov-Smirnov. 

La prueba de Anderson-Darling tiene un estadístico de `r round(anderson$statistic, 4)` y un $p$-valor de `r round(anderson$p.value, 4)`. La prueba de Kolmogorov-Smirnov tiene un estadístico de `r round(kolmo$statistic, 4)` y un $p$-valor de `r round(kolmo$p.value, 4)`. Ambas pruebas tienen un $p$-valor menor a 0.05 lo que sugiere que los residuos no siguen una distribución normal. Por lo que se puede concluir que el modelo no cumple con el supuesto de normalidad de los residuos.

#### Independencia de los Residuos.

Para la independencia de los residuos podemos usar la prueba de Durbin-Watson. Esta prueba nos permite evaluar si los residuos del modelo están correlacionados entre sí. Un valor de Durbin-Watson cercano a 2 indica que los residuos son independientes, mientras que un valor menor a 2 indica que los residuos están correlacionados positivamente y un valor mayor a 2 indica que los residuos están correlacionados negativamente.

```{r}
#| warning: false

durbin <- durbinWatsonTest(modelo_backward)
```

La prueba de Durbin-Watson nos da un estadístico de `r round(durbin$dw, 4)` ($\rho$ = `r durbin$r`) y el $p$-valor es de `r round(durbin$p, 4)`. Esto sugiere que los residuos están correlacionados entre sí. Esto se puede ver en la @fig-autocorrelacion donde se observa que desde el primer lag hay una correlación muy alta entre los residuos. Esto sugiere que los residuos no son independientes y por lo tanto el modelo no cumple con el supuesto de independencia de los residuos. 

```{r}
#| fig-cap: "Autocorrelación de los Residuos."
#| label: fig-autocorrelacion

ggAcf(modelo_backward$residuals, lag.max = 20) +
    labs(title = "",
         x = "Lags",
         y = "Autocorrelación") +
    theme_minimal()
```

### Predicción de la Esperanza de Vida.

Dado que teniamos 10 observaciones donde no teníamos la esperanza de vida, se procederá a predecir la esperanza de vida usando el modelo ajustado. Esto se hará usando la función `predict` de `R` y se usará el modelo backward dado que es el mejor modelo.

En la @tbl-prediccion_cov se muestran los datos de las variables que se usarán para predecir la esperanza de vida. En la @tbl-predicciones se muestran las predicciones de la esperanza de vida y sus intervalos de predicción al 95% de confianza.

```{r}
#| warning: false
#| tbl-cap: "Covariables para la predicción."
#| label: tbl-prediccion_cov

pred_data <- imp_data[rows_to_predict, -18]

pred_data <- pred_data %>%
    mutate(Status = as.factor(Status)) %>%
    mutate(Status = dplyr::recode(Status, "Developed" = 1, "Developing" = 0))

# Predecir la esperanza de vida
predicciones <- predict(modelo_backward, newdata = pred_data, 
                        interval = "prediction") %>%
  as.data.frame() 

# Mostramos los datos

predicciones_df <- data.frame(Country = datos$Country[rows_to_predict],
                               Year = datos$Year[rows_to_predict],
                               Prediccion = predicciones["fit"],
                               Inferior = predicciones["lwr"],
                               Superior = predicciones["upr"]) %>%
                    rename(Prediccion = fit,
                           Inferior = lwr,
                           Superior = upr)

predicciones_df <- predicciones_df %>%
    mutate(Prediccion = round(Prediccion, 4)) %>%
    arrange(desc(Prediccion))

pred_data %>%
  kable() %>%
  kable_styling("striped", full_width = F) %>%
  column_spec(1, bold = T) 
```

```{r}
#| tbl-cap: "Predicciones de la Esperanza de Vida."
#| label: tbl-predicciones

predicciones_df %>%
  kable() %>%
  kable_styling("striped", full_width = F) %>%
  column_spec(1, bold = T)
```

## Componentes Principales.

Se ajustará un modelo usando componentes principales sobre las variables predictorías numéricas.

```{r}
#| warning: false
#| fig-cap: "Componentes Principales."
#| fig-subcap:
#|    - "Gráfico de codo de los componentes principales."
#|    - "Biplot de los dos primeros componentes principales."
#| label: fig-componentes_codo
#| fig-width: 10

componentes <- princomp(imp_data[, c(-17, -18)], 
                        cor = TRUE)

variance <- componentes$sdev^2 / sum(componentes$sdev^2)

qplot(c(1:length(variance)),
      variance) +
    geom_bar(stat = "identity", fill = "steelblue") +
    geom_line() +
    geom_point() +
    geom_text(aes(label = paste(cumsum(round(variance, 3))* 100, "%")), vjust = -0.5, size = 3) +
    labs(title = "",
         x = "Componentes",
         y = "Varianza Explicada") +
    theme_minimal()

ggbiplot(componentes, 
         var.scale = 1,
         scale = 1,
         var.axes = T,
         ellipse = T,
         obs.scale = 5,
         varname.adjust = 2,
         varname.abbrev = F,
         alpha = 0.15,
         varname.size = 2.5,
         circle = T) +
    labs(title = "",
         x = "Componente 1",
         y = "Componente 2") +
    xlim(-250, 200) +
    ylim(-50, 80) +
    theme_minimal()
```

En la @fig-componentes_codo-1 se observa el gráfico de codo de los componentes principales. Usaremos 11 componentes principales dado que explican el 90% de la varianza. En @fig-componentes_codo-2 se observa el biplot de los dos primeros componentes principales. Se observa que los componentes principales son lineales y que los datos parecen estar bien distribuidos en el espacio de los componentes principales. Vemos igualmente la correlación entre las variables en su representación en el espacio de los componentes principales.

```{r}
#| warning: false
#| tbl-cap: "Modelo de Regresión Lineal con Componentes Principales."
#| label: tbl-modelo_pca

# LM con componentes principales
# Ajustar el modelo de componentes principales
Life_expectancy <-  imp_data[,c(-17)]$Life_expectancy

modelo_pca <- lm(Life_expectancy ~ ., 
                 data = data.frame(componentes$scores[, 1:11]))

modelsummary(list( "Modelo PCA" = modelo_pca), 
             fmt = fmt_decimal(9, 4), statistic = c("conf.int",
                           "std.error", 
                           "statistic",
                           "p.value"),
             stars = T,
             shape = term ~ model + statistic
             )
```

En nuestro resumen de la @tbl-modelo_pca se observa que el modelo PCA es significativo con un $F =$ `r round(summary(modelo_pca)$fstatistic[1], 2)` y con `r summary(modelo_pca)$fstatistic[2]` y `r summary(modelo_pca)$fstatistic[3]` grados de libertad, su $p$-valor es $< 2.2e-16$. El $R^2$ ajustado es `r round(summary(modelo_pca)$adj.r.squared, 4)`, siendo ligeramente menor al del mejor modelo de regresión que se obtuvo con la selección de variables. Dado que no podemos comparar directamente los modelos dado que sus variables son distintas el críterio para su comparación será el BIC. En el cuál el modelo usando 11 componentes principales es el peor con un BIC de `r round(BIC(modelo_pca), 2)` y el modelo de regresión lineal backward es el mejor con un BIC de `r round(BIC(modelo_backward), 2)`. Por lo que se puede concluir que el modelo PCA no es mejor que el modelo de regresión lineal con selección de variables.

A pesar de que el análisis de Componentes Principales es una gran herramienta para la reducción de variables almente correlacionadas, poco o nulo efecto tiene cuando este proceso de eliminación de variables se hace desde el análisis exploratorio. Esto se debe a que el PCA no es capaz de eliminar variables que no aportan información al modelo, sino que simplemente las transforma en componentes ortogonales. Por lo que el PCA no es una buena herramienta para la selección de variables en este caso. Sin embargo, para analisis donde el número de variables aumenta considerablemente su uso es más eficaz y recomendable.